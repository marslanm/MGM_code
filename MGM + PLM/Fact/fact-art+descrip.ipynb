{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pathlib import Path\n",
    "import os\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "root = Path('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {'low': 0, 'mixed': 1, 'high': 2}\n",
    "classes = list(encoder.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model article bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_article = pd.read_pickle(root / 'probability/bert-base-uncased_train_prob_fact_article.pkl')\n",
    "X_test_article = pd.read_pickle(root / 'probability/bert-base-uncased_test_prob_fact_article.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model description debert v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_des = pd.read_pickle(root / 'probability/deberta-v3-base_train_prob_fact_description.pkl')\n",
    "X_test_des = pd.read_pickle(root / 'probability/deberta-v3-base_test_prob_fact_description.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset(df, df_1):\n",
    "    df = df.merge(df_1, on=['website', 'target'])\n",
    "    df['low'] = df['low_x'] + df['low_y']\n",
    "    df['mixed'] = df['mixed_x'] + df['mixed_y']\n",
    "    df['high'] = df['high_x'] + df['high_y']\n",
    "    df['low'] /=2\n",
    "    df['mixed'] /=2\n",
    "    df['high'] /=2\n",
    "    return df[['target', 'website'] + classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = merge_dataset(X_train_article, X_train_des)\n",
    "X_test = merge_dataset(X_test_article, X_test_des)\n",
    "y_train = X_train['target']\n",
    "y_test = X_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>website</th>\n",
       "      <th>low</th>\n",
       "      <th>mixed</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>inthesetimes.com</td>\n",
       "      <td>0.041575</td>\n",
       "      <td>0.041129</td>\n",
       "      <td>0.917296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>alreporter.com</td>\n",
       "      <td>0.129161</td>\n",
       "      <td>0.184921</td>\n",
       "      <td>0.685918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>nymag.com</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>0.943082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>investopedia.com</td>\n",
       "      <td>0.027289</td>\n",
       "      <td>0.040707</td>\n",
       "      <td>0.932004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>newpol.org</td>\n",
       "      <td>0.030245</td>\n",
       "      <td>0.040960</td>\n",
       "      <td>0.928795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>mixed</td>\n",
       "      <td>theamericanmirror.com</td>\n",
       "      <td>0.153471</td>\n",
       "      <td>0.436085</td>\n",
       "      <td>0.410444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>high</td>\n",
       "      <td>americanmilitarynews.com</td>\n",
       "      <td>0.098004</td>\n",
       "      <td>0.308399</td>\n",
       "      <td>0.593597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>low</td>\n",
       "      <td>researchantisemitism.ca</td>\n",
       "      <td>0.550774</td>\n",
       "      <td>0.306654</td>\n",
       "      <td>0.142572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>mixed</td>\n",
       "      <td>taiwannews.com.tw</td>\n",
       "      <td>0.140939</td>\n",
       "      <td>0.570158</td>\n",
       "      <td>0.288903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>mixed</td>\n",
       "      <td>conservativetoday.com</td>\n",
       "      <td>0.351179</td>\n",
       "      <td>0.429893</td>\n",
       "      <td>0.218927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>773 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                   website      low    mixed     high\n",
       "0     high          inthesetimes.com 0.041575 0.041129 0.917296\n",
       "1     high            alreporter.com 0.129161 0.184921 0.685918\n",
       "2     high                 nymag.com 0.016432 0.040486 0.943082\n",
       "3     high          investopedia.com 0.027289 0.040707 0.932004\n",
       "4     high                newpol.org 0.030245 0.040960 0.928795\n",
       "..     ...                       ...      ...      ...      ...\n",
       "768  mixed     theamericanmirror.com 0.153471 0.436085 0.410444\n",
       "769   high  americanmilitarynews.com 0.098004 0.308399 0.593597\n",
       "770    low   researchantisemitism.ca 0.550774 0.306654 0.142572\n",
       "771  mixed         taiwannews.com.tw 0.140939 0.570158 0.288903\n",
       "772  mixed     conservativetoday.com 0.351179 0.429893 0.218927\n",
       "\n",
       "[773 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'C': 0.025920931494754832, 'tol': 6.802290436130853e-05, 'fit_intercept': True,\n",
    "          'solver': 'sag', 'max_iter': 251, 'class_weight': 'balanced', 'penalty': None, 'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8421052631578947\n",
      "Macro-F1 Score: 0.7972049261160651\n",
      "Average Recall: 0.7654135338345865\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(**best_params)\n",
    "clf.fit(X_train[classes], X_train['target'])\n",
    "y_pred = clf.predict(X_test[classes])\n",
    "y_test = X_test['target']\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "avg_recall = recall_score(y_test, y_pred, average='macro')\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Macro-F1 Score:\", macro_f1)\n",
    "print(\"Average Recall:\", avg_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_models_file(X_train, num_model='M1'):\n",
    "    files = []\n",
    "    renames = {'logit_1': 'low', 'logit_2':'high', 'logit_3':'mixed'}\n",
    "    for file in os.listdir(root / 'step_3' / num_model):\n",
    "        if file.endswith('csv'):\n",
    "            df = pd.read_csv(root / 'step_3' / num_model / file)\n",
    "            df.rename(columns=renames, inplace=True)\n",
    "            df['target'] = None\n",
    "            for index, row in df.iterrows():\n",
    "                df.iloc[index, -1] = row.index[row[1:].argmax() + 1]\n",
    "            df = pd.concat([X_train, df])\n",
    "            files.append(df)\n",
    "    \n",
    "    return files\n",
    "\n",
    "def evaluate(files: list[pd.DataFrame], X_test: pd.DataFrame, params_log_reg={}):\n",
    "    accuracy_list = []\n",
    "    macro_f1_list = []\n",
    "    avg_recall_list = []\n",
    "    for index, X_train in enumerate(files):\n",
    "        clf = LogisticRegression(**params_log_reg)\n",
    "        clf.fit(X_train[classes], X_train['target'])\n",
    "        y_pred = clf.predict(X_test[classes])\n",
    "        y_test = X_test['target']\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        avg_recall = recall_score(y_test, y_pred, average='macro')\n",
    "        accuracy_list.append(accuracy), macro_f1_list.append(macro_f1), avg_recall_list.append(avg_recall)\n",
    "        print(f'Index: {index}')\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Macro-F1 Score:\", macro_f1)\n",
    "        print(\"Average Recall:\", avg_recall)\n",
    "    accuracy_std = np.std(accuracy_list)\n",
    "    macro_f1_std = np.std(macro_f1_list)\n",
    "    avg_recall_std = np.std(avg_recall_list)\n",
    "\n",
    "    print(f\"Standard Deviation of Accuracy: {accuracy_std}\")\n",
    "    print(f\"Standard Deviation of Macro-F1 Score: {macro_f1_std}\")\n",
    "    print(f\"Standard Deviation of Average Recall: {avg_recall_std}\")\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Accuracy: 0.7602339181286549\n",
      "Macro-F1 Score: 0.7151446683299434\n",
      "Average Recall: 0.6947786131996659\n",
      "Index: 1\n",
      "Accuracy: 0.7953216374269005\n",
      "Macro-F1 Score: 0.713952401276345\n",
      "Average Recall: 0.6708437761069339\n",
      "Index: 2\n",
      "Accuracy: 0.8362573099415205\n",
      "Macro-F1 Score: 0.7827733961509938\n",
      "Average Recall: 0.7479114452798662\n",
      "Index: 3\n",
      "Accuracy: 0.8421052631578947\n",
      "Macro-F1 Score: 0.7940487572774568\n",
      "Average Recall: 0.7566833751044276\n",
      "Index: 4\n",
      "Accuracy: 0.8304093567251462\n",
      "Macro-F1 Score: 0.7783883679847806\n",
      "Average Recall: 0.7416040100250626\n",
      "Standard Deviation of Accuracy: 0.030944459778533228\n",
      "Standard Deviation of Macro-F1 Score: 0.03492623457819747\n",
      "Standard Deviation of Average Recall: 0.03351404627396947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = read_models_file(X_train, num_model='M1')\n",
    "evaluate(files, X_test, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Accuracy: 0.8304093567251462\n",
      "Macro-F1 Score: 0.784319899799776\n",
      "Average Recall: 0.7503341687552213\n",
      "Index: 1\n",
      "Accuracy: 0.8304093567251462\n",
      "Macro-F1 Score: 0.784319899799776\n",
      "Average Recall: 0.7503341687552213\n",
      "Index: 2\n",
      "Accuracy: 0.8304093567251462\n",
      "Macro-F1 Score: 0.784319899799776\n",
      "Average Recall: 0.7503341687552213\n",
      "Index: 3\n",
      "Accuracy: 0.8304093567251462\n",
      "Macro-F1 Score: 0.784319899799776\n",
      "Average Recall: 0.7503341687552213\n",
      "Index: 4\n",
      "Accuracy: 0.8304093567251462\n",
      "Macro-F1 Score: 0.784319899799776\n",
      "Average Recall: 0.7503341687552213\n",
      "Standard Deviation of Accuracy: 0.0\n",
      "Standard Deviation of Macro-F1 Score: 0.0\n",
      "Standard Deviation of Average Recall: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = read_models_file(X_train, num_model='M2')\n",
    "evaluate(files, X_test, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Accuracy: 0.8245614035087719\n",
      "Macro-F1 Score: 0.7771583107967547\n",
      "Average Recall: 0.7471595655806181\n",
      "Index: 1\n",
      "Accuracy: 0.8245614035087719\n",
      "Macro-F1 Score: 0.7771583107967547\n",
      "Average Recall: 0.7471595655806181\n",
      "Index: 2\n",
      "Accuracy: 0.8245614035087719\n",
      "Macro-F1 Score: 0.7771583107967547\n",
      "Average Recall: 0.7471595655806181\n",
      "Index: 3\n",
      "Accuracy: 0.8304093567251462\n",
      "Macro-F1 Score: 0.784319899799776\n",
      "Average Recall: 0.7503341687552213\n",
      "Index: 4\n",
      "Accuracy: 0.8304093567251462\n",
      "Macro-F1 Score: 0.782002754278969\n",
      "Average Recall: 0.7503341687552213\n",
      "Standard Deviation of Accuracy: 0.002864900283956906\n",
      "Standard Deviation of Macro-F1 Score: 0.00303077635246345\n",
      "Standard Deviation of Average Recall: 0.0015552315827194727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = read_models_file(X_train, num_model='M3')\n",
    "evaluate(files, X_test, best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
