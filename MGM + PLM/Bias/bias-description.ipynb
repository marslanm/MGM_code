{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:03:37.448353Z","iopub.status.busy":"2024-06-02T20:03:37.448083Z","iopub.status.idle":"2024-06-02T20:03:37.666900Z","shell.execute_reply":"2024-06-02T20:03:37.666117Z","shell.execute_reply.started":"2024-06-02T20:03:37.448329Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import os\n","import json\n","from pathlib import Path\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","import pickle\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n","from torch.utils.data import DataLoader, Dataset\n","import torch\n","from torch import nn\n","import transformers\n","from statistics import mode\n","import wandb\n","import warnings\n","from sklearn.linear_model import LogisticRegression\n","warnings.simplefilter(\"ignore\")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:09:21.094290Z","iopub.status.busy":"2024-06-02T20:09:21.093485Z","iopub.status.idle":"2024-06-02T20:09:21.098823Z","shell.execute_reply":"2024-06-02T20:09:21.097854Z","shell.execute_reply.started":"2024-06-02T20:09:21.094260Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    encoder = {'left': 0, 'center': 1, 'right': 2}\n","    target = 'bias'\n","    max_len = 256\n","    input_text='description'\n","    text_col = 'wiki_text_lemmatization'\n","    logging_steps = 15"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:03:37.676473Z","iopub.status.busy":"2024-06-02T20:03:37.675920Z","iopub.status.idle":"2024-06-02T20:03:37.708141Z","shell.execute_reply":"2024-06-02T20:03:37.707447Z","shell.execute_reply.started":"2024-06-02T20:03:37.676443Z"},"trusted":true},"outputs":[],"source":["root = Path('')\n","df = pd.read_pickle(root / 'Data/media_description.pkl')\n","df['website'] = df['source_url'].str.strip('https://').str.strip('www.')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:03:37.709312Z","iopub.status.busy":"2024-06-02T20:03:37.709062Z","iopub.status.idle":"2024-06-02T20:03:37.719174Z","shell.execute_reply":"2024-06-02T20:03:37.718309Z","shell.execute_reply.started":"2024-06-02T20:03:37.709291Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 45 µs, sys: 8 µs, total: 53 µs\n","Wall time: 57 µs\n"]}],"source":["%%time\n","from multiprocessing import Pool, cpu_count\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'\n","# Function to process each row\n","def process_row(row):\n","    text = row[CFG.text_col]\n","    label = row[CFG.target]\n","    label = np.vectorize(lambda item: CFG.encoder[item])(label)\n","    \n","    encoding = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=CFG.max_len,\n","        return_token_type_ids=False,\n","        padding='max_length',\n","        truncation=True,\n","        return_attention_mask=True,\n","        return_tensors='pt'\n","    )\n","    \n","    result = {\n","        'text': text,\n","        'input_ids': encoding['input_ids'].flatten().tolist(),\n","        'attention_mask': encoding['attention_mask'].flatten().tolist(),\n","        'label': label.tolist()\n","    }\n","    \n","    return result\n","\n","def process_chunk(df_chunk):\n","    return df_chunk.apply(process_row, axis=1)\n","\n","# Function to apply processing in parallel\n","def parallelize_dataframe(df, func, n_cores=cpu_count()):\n","    df_split = np.array_split(df, n_cores)\n","    pool = Pool(n_cores)\n","    results = list(tqdm(pool.imap(func, df_split), total=len(df_split)))\n","    pool.close()\n","    pool.join()\n","    return pd.concat(results)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:03:37.720455Z","iopub.status.busy":"2024-06-02T20:03:37.720178Z","iopub.status.idle":"2024-06-02T20:03:37.737660Z","shell.execute_reply":"2024-06-02T20:03:37.736815Z","shell.execute_reply.started":"2024-06-02T20:03:37.720432Z"},"trusted":true},"outputs":[],"source":["with open(root / 'bias/bias_distribution.json') as f:\n","    split = json.load(f)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:03:37.740550Z","iopub.status.busy":"2024-06-02T20:03:37.740282Z","iopub.status.idle":"2024-06-02T20:03:37.747192Z","shell.execute_reply":"2024-06-02T20:03:37.746214Z","shell.execute_reply.started":"2024-06-02T20:03:37.740528Z"},"trusted":true},"outputs":[],"source":["class ArticlesDataset(Dataset):\n","    def __init__(self, df: pd.DataFrame):\n","        self.df = df\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        label = self.df.iloc[idx, -1]\n","        attention_mask = self.df.iloc[idx, -2]\n","        input_ids = self.df.iloc[idx, -3]\n","        text = self.df.iloc[idx, -4]\n","        return {\n","            'text': text,\n","            'input_ids': torch.tensor(input_ids),\n","            'attention_mask': torch.tensor(attention_mask),\n","            'label': torch.tensor(label).to(dtype=torch.int8)\n","        }"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:03:37.748518Z","iopub.status.busy":"2024-06-02T20:03:37.748252Z","iopub.status.idle":"2024-06-02T20:03:38.733837Z","shell.execute_reply":"2024-06-02T20:03:38.732531Z","shell.execute_reply.started":"2024-06-02T20:03:37.748497Z"},"trusted":true},"outputs":[],"source":["!mkdir probability"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:12:30.682484Z","iopub.status.busy":"2024-06-02T20:12:30.682127Z","iopub.status.idle":"2024-06-02T20:12:30.712639Z","shell.execute_reply":"2024-06-02T20:12:30.711611Z","shell.execute_reply.started":"2024-06-02T20:12:30.682456Z"},"trusted":true},"outputs":[],"source":["class NewsModel:\n","    def __init__(self, model=None, tokenizer=None, target='bias',\n","                input_text =CFG.input_text) -> None:\n","        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.target = target\n","        self.input_text = input_text\n","    \n","    \n","    def create_dataset(self, X_train, X_test):\n","        self.train_dataset = ArticlesDataset(X_train)\n","        self.test_dataset = ArticlesDataset(X_test)\n","        self.X_train = X_train.copy()\n","        self.X_test = X_test.copy()\n","        \n","    \n","    def train_model(self, tokenizer=None, model_name='bert-base-uncased', \n","                batch_size=100, epochs=4, learning_rate=3e-5):\n","        if self.tokenizer is None:\n","            self.tokenizer = tokenizer\n","        self.model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name,\n","                                                                   num_labels=3).to(self.device)\n","        self.model_name = model_name.strip('microsoft/')\n","        \n","        \n","        training_args = transformers.TrainingArguments(\n","            output_dir='./results',\n","            num_train_epochs=epochs,\n","            per_device_train_batch_size=batch_size,\n","            learning_rate=learning_rate,\n","            logging_dir='./logs',\n","            logging_steps=CFG.logging_steps,\n","    #         evaluation_strategy=\"steps\",\n","            save_steps=15_000,\n","            fp16=True,\n","        )\n","        self.trainer = transformers.Trainer(\n","            model=self.model,\n","            args=training_args,\n","            train_dataset=self.train_dataset,\n","    #         eval_dataset=self.test_dataset,\n","        )\n","        self.trainer.train()\n","        \n","    def save_models(self):\n","        self.model.save_pretrained(f'./models/{self.model_name}_model_{CFG.target}_{self.input_text}')\n","        self.tokenizer.save_pretrained(f'./models/{self.model_name}_model_{CFG.target}_{self.input_text}')\n","        with open(f'./models/{self.model_name}_log_reg_model_{CFG.target}_{self.input_text}', 'wb') as f:\n","            pickle.dump(self.clf, f)\n","    \n","    def restore_models(self, tokenizer, model_name, root):\n","        self.model_name = model_name.strip('microsoft/')\n","        self.model = transformers.AutoModelForSequenceClassification.from_pretrained(\n","            root / 'bias_predict' / f'models/{self.model_name}_model_{CFG.target}_{self.input_text}', num_labels=3)\n","        self.tokenizer = tokenizer.from_pretrained(root / 'bias_predict' /  f'models/{self.model_name}_model_{CFG.target}_{self.input_text}')\n","        with open(root / 'bias_predict' /  f'models/{self.model_name}_log_reg_model_{CFG.target}_{self.input_text}', 'rb') as f:\n","            self.clf = pickle.load(f)\n","        \n","        self.trainer = transformers.Trainer(\n","            model=self.model)\n","        \n","        \n","    def softmax(self, x):\n","        x = torch.tensor(x)\n","        if len(x.shape) == 1:\n","            # Apply softmax on a 1D tensor by converting it to a 2D tensor\n","            x = x.unsqueeze(0)  # Add a batch dimension\n","            s = nn.Softmax(dim=1)\n","            result = s(x).squeeze(0).numpy()\n","            return result\n","        elif len(x.shape) == 2:\n","            # Apply softmax on a 2D tensor\n","            s = nn.Softmax(dim=1)\n","            return s(x).numpy()\n","\n","        \n","    def soft_voting_for_article(self, df:pd.DataFrame):\n","        groups = df['source_url'].unique()\n","        classes = list(CFG.encoder.keys())\n","        dst = {'target': [], 'website': []} | {k:[] for k in classes}\n","        for group in groups:\n","            mask = df['source_url'] == group\n","            dst['website'].append(df.loc[mask, 'website'].tolist()[0])\n","            dst['target'].append(df.loc[mask, self.target].tolist()[0])\n","            logits = df.loc[mask, classes].sum(axis=0)\n","            pred = self.softmax(logits)\n","            for class_, probability in zip(classes, pred):\n","                dst[class_].append(probability)\n","        df = pd.DataFrame(dst)\n","        return df\n","    \n","    \n","    def create_dataset_for_log_reg(self, dataset_to_predict='train'):\n","        self.model.eval()\n","        if dataset_to_predict == 'train':\n","            predictions = self.trainer.predict(self.train_dataset)\n","            df = self.X_train.copy()\n","        else:\n","            predictions = self.trainer.predict(self.test_dataset)\n","            df = self.X_test.copy()\n","        pred = self.softmax(predictions.predictions)\n","        target_decoder = {v: k for k, v in CFG.encoder.items()}\n","        decoder_func = np.vectorize(lambda item: target_decoder[item])\n","        if self.input_text == 'article':\n","            classes = list(CFG.encoder.keys())\n","            df[list(CFG.encoder.keys())] = pred\n","            df['pred'] = decoder_func(pred.argmax(axis=1))\n","            df = self.soft_voting_for_article(df)    \n","        \n","        else:\n","#             df = pd.DataFrame(pred, columns=list(CFG.encoder.keys()))\n","            df[list(CFG.encoder.keys())] = pred\n","            df['target'] = df[CFG.target].copy()\n","            columns = ['target', 'website'] + list(CFG.encoder.keys())\n","            df = df[columns]\n","        return df\n","        \n","    \n","    def prepare_dataset_for_log_reg(self):\n","        X_train = self.create_dataset_for_log_reg(dataset_to_predict='train')\n","        X_test = self.create_dataset_for_log_reg(dataset_to_predict='test')\n","        df_2 = pd.read_csv(root / f'{self.target}/train.csv')\n","        df_2 = df_2[~df_2['website'].isin(X_train['website'])]\n","        X_train = pd.concat([X_train, df_2]).reset_index(drop=True)\n","        \n","        df_2 = pd.read_csv(root / f'{self.target}/test.csv')\n","        df_2 = df_2[~df_2['website'].isin(X_test['website'])]\n","        X_test = pd.concat([X_test, df_2]).reset_index(drop=True)\n","        \n","        return X_train, X_test\n","    \n","    def log_reg(self):\n","        X_train, X_test = pipeline.prepare_dataset_for_log_reg()\n","        clf = LogisticRegression()\n","        clf.fit(X_train[list(CFG.encoder.keys())], X_train['target'])\n","        self.clf = clf\n","        y_pred = clf.predict(X_test[list(CFG.encoder.keys())])\n","        y_test = X_test['target']\n","        accuracy = accuracy_score(y_test, y_pred)\n","        macro_f1 = f1_score(y_test, y_pred, average='macro')\n","        avg_recall = recall_score(y_test, y_pred, average='macro')\n","        print(\"Accuracy:\", accuracy)\n","        print(\"Macro-F1 Score:\", macro_f1)\n","        print(\"Average Recall:\", avg_recall)\n","        self.save_prob(X_train, X_test)\n","    \n","    def save_prob(self, X_train, X_test):\n","        train_prob_path = f'./probability/{self.model_name}_train_prob_{self.target}_{self.input_text}.pkl'\n","        test_prob_path = f'./probability/{self.model_name}_test_prob_{self.target}_{self.input_text}.pkl'\n","        X_train.to_pickle(train_prob_path)\n","        X_test.to_pickle(test_prob_path)"]},{"cell_type":"markdown","metadata":{},"source":["### BERT"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:03:47.045281Z","iopub.status.busy":"2024-06-02T20:03:47.044919Z","iopub.status.idle":"2024-06-02T20:03:49.203564Z","shell.execute_reply":"2024-06-02T20:03:49.202333Z","shell.execute_reply.started":"2024-06-02T20:03:47.045252Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"491a16e1486247dbb77674d15d90d5ab","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d8a582cccd54d35bc1c4096e64259bf","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"525ee15a6e094e56a454efdf77782b3a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4c44f7ae3d142cca07d87cb98ec4594","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:01<00:00,  3.13it/s]\n"]}],"source":["tokenizer = transformers.BertTokenizerFast.from_pretrained('bert-base-uncased')\n","df_copy = df.copy()\n","df_processed = parallelize_dataframe(df_copy, process_chunk)\n","df['text'] = df_processed.apply(lambda x: x['text'])\n","df['input_ids'] = df_processed.apply(lambda x: x['input_ids'])\n","df['attention_mask'] = df_processed.apply(lambda x: x['attention_mask'])\n","df['label'] = df_processed.apply(lambda x: x['label'])\n","\n","X_train = df[~df['website'].isin(split['test'])]\n","X_test = df[df['website'].isin(split['test'])]"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:12:33.159224Z","iopub.status.busy":"2024-06-02T20:12:33.158912Z","iopub.status.idle":"2024-06-02T20:12:33.601992Z","shell.execute_reply":"2024-06-02T20:12:33.601010Z","shell.execute_reply.started":"2024-06-02T20:12:33.159198Z"},"trusted":true},"outputs":[],"source":["pipeline = NewsModel(target='bias',input_text=CFG.input_text, tokenizer=tokenizer)\n","pipeline.create_dataset(X_train, X_test)\n","# pipeline.restore_models(transformers.BertTokenizerFast, 'bert-base-uncased', root=root)"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:20:15.779869Z","iopub.status.busy":"2024-06-02T20:20:15.779484Z","iopub.status.idle":"2024-06-02T20:23:19.676936Z","shell.execute_reply":"2024-06-02T20:23:19.675647Z","shell.execute_reply.started":"2024-06-02T20:20:15.779838Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [100/100 02:55, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.038900</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.866000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.628700</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.416200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.251700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.148300</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.088400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.053900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.040000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.034100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8255813953488372\n","Macro-F1 Score: 0.8225125955292553\n","Average Recall: 0.8140332617065091\n"]}],"source":["pipeline.train_model(transformers.BertTokenizerFast, model_name='bert-base-uncased', batch_size=40, epochs=20, learning_rate=5e-5)\n","pipeline.log_reg()\n","pipeline.save_models()"]},{"cell_type":"markdown","metadata":{},"source":["### ROberta"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:23:32.347072Z","iopub.status.busy":"2024-06-02T20:23:32.346690Z","iopub.status.idle":"2024-06-02T20:23:34.833969Z","shell.execute_reply":"2024-06-02T20:23:34.832823Z","shell.execute_reply.started":"2024-06-02T20:23:32.347042Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2faa72872b144f1183bfc880e9e84228","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b6e7feee59b49dbbadbd212541aaba6","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69cb07ce7fef4684b32e1d1d978aa276","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"729d1120b4e146cea43c30920f24d653","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a717dab5cb554a4db9bc0f1599c1aaa0","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:01<00:00,  3.16it/s]\n"]}],"source":["model_name = 'roberta-base'\n","tokenizer = transformers.RobertaTokenizerFast.from_pretrained(model_name)\n","df_copy = df.copy()\n","df_processed = parallelize_dataframe(df_copy, process_chunk)\n","df['text'] = df_processed.apply(lambda x: x['text'])\n","df['input_ids'] = df_processed.apply(lambda x: x['input_ids'])\n","df['attention_mask'] = df_processed.apply(lambda x: x['attention_mask'])\n","df['label'] = df_processed.apply(lambda x: x['label'])\n","X_train = df[~df['website'].isin(split['test'])]\n","X_test = df[df['website'].isin(split['test'])]"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:23:43.068531Z","iopub.status.busy":"2024-06-02T20:23:43.068140Z","iopub.status.idle":"2024-06-02T20:26:33.910996Z","shell.execute_reply":"2024-06-02T20:26:33.909953Z","shell.execute_reply.started":"2024-06-02T20:23:43.068502Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4055aafc28004f3f8123857a364bca36","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [90/90 02:38, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.072900</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.833000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.510800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.302500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.205100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.111000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.074100</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.052500</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.033400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8197674418604651\n","Macro-F1 Score: 0.8131552946506461\n","Average Recall: 0.8070888172620646\n"]}],"source":["pipeline = NewsModel(target='bias',input_text=CFG.input_text, tokenizer=tokenizer)\n","pipeline.create_dataset(X_train, X_test)\n","pipeline.train_model(tokenizer, model_name=model_name, batch_size=40, epochs=18, learning_rate=5e-5)\n","pipeline.log_reg()\n","pipeline.save_models()"]},{"cell_type":"markdown","metadata":{},"source":["### distilbert"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:26:41.439563Z","iopub.status.busy":"2024-06-02T20:26:41.438873Z","iopub.status.idle":"2024-06-02T20:26:43.787562Z","shell.execute_reply":"2024-06-02T20:26:43.786377Z","shell.execute_reply.started":"2024-06-02T20:26:41.439532Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3697d43590fd42df9dd20e25ed17d4b1","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ea02d4aba254f71bf232bf3bf4bd8b2","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa2c96ba9abc4da6b5e408e5db5e7b5b","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3f30e7a333c469c917a74f2eb7b2678","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:01<00:00,  2.87it/s]\n"]}],"source":["model_name = 'distilbert-base-uncased'\n","tokenizer = transformers.DistilBertTokenizerFast.from_pretrained(model_name)\n","df_copy = df.copy()\n","df_processed = parallelize_dataframe(df_copy, process_chunk)\n","df['text'] = df_processed.apply(lambda x: x['text'])\n","df['input_ids'] = df_processed.apply(lambda x: x['input_ids'])\n","df['attention_mask'] = df_processed.apply(lambda x: x['attention_mask'])\n","df['label'] = df_processed.apply(lambda x: x['label'])\n","X_train = df[~df['website'].isin(split['test'])]\n","X_test = df[df['website'].isin(split['test'])]"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:27:00.027324Z","iopub.status.busy":"2024-06-02T20:27:00.026526Z","iopub.status.idle":"2024-06-02T20:28:24.270948Z","shell.execute_reply":"2024-06-02T20:28:24.269827Z","shell.execute_reply.started":"2024-06-02T20:27:00.027291Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [54/54 01:18, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.059600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.809900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.531800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.358900</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.260200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.813953488372093\n","Macro-F1 Score: 0.8068355119825709\n","Average Recall: 0.8025226072164026\n"]}],"source":["pipeline = NewsModel(target='bias',input_text=CFG.input_text, tokenizer=tokenizer)\n","pipeline.create_dataset(X_train, X_test)\n","pipeline.train_model(tokenizer, model_name=model_name, batch_size=70, epochs=18, learning_rate=5e-5)\n","pipeline.log_reg()\n","pipeline.save_models()"]},{"cell_type":"markdown","metadata":{},"source":["### deberta-v3"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:29:17.429199Z","iopub.status.busy":"2024-06-02T20:29:17.428352Z","iopub.status.idle":"2024-06-02T20:29:20.444498Z","shell.execute_reply":"2024-06-02T20:29:20.443069Z","shell.execute_reply.started":"2024-06-02T20:29:17.429168Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d53f069033b04ecc9252faf8756d297b","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7814fd9263804089becdb160f25b4f5a","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3de0c19cd3a84fc0ac2126ff993e494f","version_major":2,"version_minor":0},"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n"]}],"source":["model_name = 'microsoft/deberta-v3-base'\n","tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n","df_copy = df.copy()\n","df_processed = parallelize_dataframe(df_copy, process_chunk)\n","df['text'] = df_processed.apply(lambda x: x['text'])\n","df['input_ids'] = df_processed.apply(lambda x: x['input_ids'])\n","df['attention_mask'] = df_processed.apply(lambda x: x['attention_mask'])\n","df['label'] = df_processed.apply(lambda x: x['label'])\n","X_train = df[~df['website'].isin(split['test'])]\n","X_test = df[df['website'].isin(split['test'])]"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T20:29:33.000829Z","iopub.status.busy":"2024-06-02T20:29:33.000399Z","iopub.status.idle":"2024-06-02T20:34:04.047545Z","shell.execute_reply":"2024-06-02T20:34:04.046448Z","shell.execute_reply.started":"2024-06-02T20:29:33.000785Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ce0f79da76f4878a1bd876fa40f1102","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [270/270 04:17, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.107300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.088400</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.089700</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.992700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.990300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.840600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.847000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.549700</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.618600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.489800</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.430400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.611700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.393700</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.294500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.423700</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.308100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.152900</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.273900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.254300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.281100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.179200</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.179800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.158000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.110900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.132100</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.132200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.085900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8081395348837209\n","Macro-F1 Score: 0.8026433622579748\n","Average Recall: 0.7927914316411496\n"]}],"source":["pipeline = NewsModel(target='bias',input_text =CFG.input_text, tokenizer=tokenizer)\n","pipeline.create_dataset(X_train, X_test)\n","pipeline.train_model(tokenizer, model_name=model_name, batch_size=14, epochs=18, learning_rate=5e-5)\n","pipeline.log_reg()\n","pipeline.save_models()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5070509,"sourceId":8585799,"sourceType":"datasetVersion"},{"sourceId":181110607,"sourceType":"kernelVersion"},{"sourceId":181130326,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
